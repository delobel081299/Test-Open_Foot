# üèóÔ∏è PROMPTS VIBE CODING - PHASE 1 : INFRASTRUCTURE ET SETUP

## üìÖ Dur√©e : 1 semaine

## üéØ Objectifs
- Cr√©er la structure compl√®te du projet
- Configurer l'environnement de d√©veloppement
- Mettre en place les outils de base
- Pr√©parer l'architecture modulaire

---

## 1Ô∏è‚É£ Prompt Initial - Structure du Projet

```
Je d√©veloppe une plateforme d'analyse vid√©o IA pour le football professionnel.

Cr√©e-moi une structure de projet Python moderne et professionnelle avec :

STRUCTURE :
- Architecture modulaire claire (src/core, src/modules/*, src/api, src/web)
- S√©paration des couches (pr√©sentation, m√©tier, donn√©es)
- Pattern Repository pour l'acc√®s aux donn√©es
- Configuration centralis√©e

OUTILS :
- Poetry pour la gestion des d√©pendances
- Pre-commit hooks (black, flake8, mypy, isort)
- Docker multi-stage pour optimisation
- Docker Compose pour d√©veloppement local
- Makefile avec commandes utiles

QUALIT√â CODE :
- Type hints partout (Python 3.11+)
- Docstrings Google style
- Tests unitaires pytest (structure miroir)
- Coverage minimum 80%
- Logging structur√© avec loguru

MODULES PRINCIPAUX :
1. video_processing : traitement vid√©o (FFmpeg, OpenCV)
2. detection : d√©tection objets (YOLO, tracking)
3. pose_estimation : analyse biom√©canique (MediaPipe)
4. analysis : logique m√©tier football
5. ml_models : mod√®les ML/DL
6. api : API REST FastAPI
7. storage : gestion fichiers (S3, local)

G√©n√®re tous les fichiers de base avec exemples concrets.
```

## 2Ô∏è‚É£ Prompt Configuration Avanc√©e

```
Ajoute √† mon projet une configuration compl√®te et professionnelle :

1. CONFIGURATION MULTI-ENVIRONNEMENTS :
   - Fichier .env.example document√©
   - Config Pydantic BaseSettings
   - Validation types et ranges
   - Support dev/staging/prod
   
2. SECRETS MANAGEMENT :
   - AWS Secrets Manager integration
   - Rotation automatique
   - Fallback local pour dev

3. MONITORING :
   - Prometheus metrics
   - Health checks endpoints
   - Performance profiling hooks
   - Sentry error tracking

4. EXEMPLE CONFIG :
```python
class VideoConfig(BaseSettings):
    max_file_size: int = Field(500_000_000, ge=0)  # 500MB
    supported_formats: List[str] = ["mp4", "avi", "mov"]
    fps_extraction: int = Field(30, ge=15, le=60)
    gpu_enabled: bool = True
    
class MLConfig(BaseSettings):
    model_confidence_threshold: float = Field(0.7, ge=0.0, le=1.0)
    batch_size: int = Field(32, ge=1)
    device: str = Field("cuda", regex="^(cuda|cpu)$")
```

Impl√©mente le syst√®me complet avec hot-reload en dev.
```

## 3Ô∏è‚É£ Prompt Docker Production-Ready

```
Configure Docker pour mon application d'analyse vid√©o football :

1. DOCKERFILE MULTI-STAGE :
   - Stage 1: Builder avec d√©pendances compil√©es
   - Stage 2: Runtime optimis√© (alpine si possible)
   - Cache Poetry dependencies
   - Non-root user
   - GPU support (nvidia-docker)

2. DOCKER COMPOSE :
   - Services : app, postgres, redis, minio (S3 local)
   - Networks isol√©s
   - Volumes pour persistance
   - Healthchecks
   - Restart policies

3. OPTIMISATIONS :
   - Layers caching intelligent
   - Multi-platform build (AMD64/ARM64)
   - Security scanning (Trivy)
   - Size < 2GB avec mod√®les ML

4. KUBERNETES READY :
   - ConfigMaps/Secrets structure
   - Readiness/Liveness probes
   - Resource limits
   - HPA configuration

G√©n√®re tous les fichiers avec best practices 2024.
```

## 4Ô∏è‚É£ Prompt Base de Donn√©es

```
Configure une architecture de donn√©es robuste pour mon syst√®me :

1. POSTGRESQL SCHEMA :
```sql
-- Utilisateurs et organisations
CREATE TABLE organizations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    type VARCHAR(50), -- 'club', 'academy', 'recruiter'
    subscription_tier VARCHAR(50),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID REFERENCES organizations(id),
    email VARCHAR(255) UNIQUE NOT NULL,
    role VARCHAR(50), -- 'admin', 'coach', 'analyst', 'player'
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Analyses vid√©o
CREATE TABLE video_analyses (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    video_url TEXT NOT NULL,
    status VARCHAR(50), -- 'pending', 'processing', 'completed', 'failed'
    metadata JSONB, -- dur√©e, r√©solution, fps, etc.
    created_at TIMESTAMPTZ DEFAULT NOW(),
    completed_at TIMESTAMPTZ
);

-- R√©sultats d√©taill√©s
CREATE TABLE analysis_results (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    analysis_id UUID REFERENCES video_analyses(id),
    player_id UUID,
    action_type VARCHAR(100), -- 'pass', 'shot', 'dribble', etc.
    timestamp_ms INTEGER,
    biomechanics_score FLOAT,
    tactical_score FLOAT,
    details JSONB, -- Donn√©es compl√®tes
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

2. MIGRATIONS ALEMBIC :
   - Auto-g√©n√©ration depuis SQLAlchemy
   - Rollback strategy
   - Data migrations

3. REPOSITORY PATTERN :
   - Interface abstraite
   - Impl√©mentation PostgreSQL
   - Cache Redis layer
   - Tests avec fixtures

Impl√©mente avec SQLAlchemy 2.0 async.
```

## 5Ô∏è‚É£ Prompt API FastAPI

```
D√©veloppe une API REST professionnelle FastAPI pour mon syst√®me :

1. STRUCTURE API :
```python
# Endpoints principaux
POST   /api/v1/analyses/upload       # Upload vid√©o + lancement analyse
GET    /api/v1/analyses/{id}         # Statut et r√©sultats
GET    /api/v1/analyses/{id}/report  # Rapport PDF
WS     /api/v1/analyses/{id}/stream  # Updates temps r√©el

POST   /api/v1/auth/login
POST   /api/v1/auth/refresh
GET    /api/v1/users/me

GET    /api/v1/stats/player/{id}     # Stats agr√©g√©es joueur
GET    /api/v1/stats/team/{id}       # Stats √©quipe
```

2. FEATURES AVANC√âES :
   - Pagination avec curseurs
   - Filtering/Sorting dynamique
   - Rate limiting par tier
   - Versioning API
   - OpenAPI 3.1 avec exemples

3. UPLOAD OPTIMIS√â :
   - Chunked upload pour gros fichiers
   - Reprise apr√®s interruption
   - Progress tracking
   - Validation format/taille

4. AUTHENTIFICATION :
   - JWT avec refresh tokens
   - OAuth2 pour int√©grations
   - API keys pour B2B
   - RBAC complet

5. MIDDLEWARE :
   - Request ID tracking
   - Performance logging
   - CORS configuration
   - Compression gzip

G√©n√®re code complet avec tests d'int√©gration.
```

## 6Ô∏è‚É£ Prompt Testing Framework

```
Mets en place une infrastructure de tests compl√®te :

1. STRUCTURE TESTS :
```
tests/
‚îú‚îÄ‚îÄ unit/           # Tests unitaires rapides
‚îú‚îÄ‚îÄ integration/    # Tests avec DB/services
‚îú‚îÄ‚îÄ e2e/           # Tests bout en bout
‚îú‚îÄ‚îÄ fixtures/      # Donn√©es de test
‚îî‚îÄ‚îÄ conftest.py    # Configuration pytest
```

2. FIXTURES FOOTBALL :
   - Vid√©os de test (passes, tirs, dribbles)
   - Annotations ground truth
   - Profils joueurs types
   - Sc√©narios match complets

3. MOCKS INTELLIGENTS :
   - ML models responses
   - Video processing
   - External APIs
   - AWS services

4. TESTS PERFORMANCE :
   - Locust pour charge API
   - Memory profiling
   - GPU utilization
   - Latence processing

5. CI/CD GITHUB ACTIONS :
```yaml
- Tests parall√®les par module
- Coverage report + badge
- Smoke tests GPU
- Build & push Docker
- Deploy staging auto
```

Cr√©e l'infrastructure compl√®te avec exemples.
```

## 7Ô∏è‚É£ Prompt Logging & Monitoring

```
Configure un syst√®me de logging et monitoring production-grade :

1. LOGGING STRUCTUR√â :
```python
from loguru import logger

# Configuration par module
logger.add(
    "logs/app_{time}.log",
    rotation="1 day",
    retention="30 days",
    format="{time} | {level} | {module} | {message}",
    serialize=True  # JSON pour parsing
)

# Contexte m√©tier
@logger.contextualize
def analyze_video(video_id: str, user_id: str):
    logger.bind(video_id=video_id, user_id=user_id)
    logger.info("Starting video analysis")
```

2. M√âTRIQUES PROMETHEUS :
   - Latence par endpoint
   - Queue size processing
   - GPU/CPU utilization
   - Model inference time
   - Success/error rates

3. TRACING OPENTELEMETRY :
   - Trace complet pipeline
   - Span par √©tape
   - Correlation IDs
   - Export Jaeger

4. DASHBOARDS GRAFANA :
   - Vue syst√®me global
   - Analyse par client
   - Alerting intelligent
   - SLO tracking

5. ERROR TRACKING :
   - Sentry integration
   - Custom fingerprinting
   - User context
   - Release tracking

Impl√©mente avec exemples concrets football.
```

## üéÆ Commandes Utiles Make

```makefile
# Development
make dev          # Lance tous les services locaux
make test         # Execute tous les tests
make lint         # V√©rifie la qualit√© du code
make format       # Formate le code

# Docker
make build        # Build images Docker
make push         # Push vers registry
make deploy-staging # D√©ploie en staging

# Database
make db-migrate   # Applique migrations
make db-seed      # Charge donn√©es test

# ML
make download-models  # T√©l√©charge mod√®les pre-trained
make train-custom    # Lance entra√Ænement custom
```

## üìù Notes pour l'√©quipe

1. **Commencer par** : Structure de base + Docker
2. **Priorit√©** : API upload vid√©o fonctionnelle
3. **Tests** : √âcrire tests en parall√®le du code
4. **Documentation** : Mettre √† jour au fur et √† mesure
5. **Reviews** : Code review syst√©matique via PR 